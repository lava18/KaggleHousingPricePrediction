titanic3 %>%
select(age) %>%
ggplot(aes(x=age)) + geom_histogram()
# After the imputation
titanic3$age[is.na(titanic3$age)] = mean(titanic3$age, na.rm=TRUE)
titanic3 %>%
select(age) %>%
ggplot(aes(x=age)) + geom_histogram()
library(Hmisc)
# Your code here
library(dplyr)
library(PASWR)
library(VIM)
library(mice)
library(ggplot2)
library(Hmisc)
set.seed(0)
imputed.age = impute(titanic3$age, "random")
class(imputed.age)
data.frame(imputed.age)
data.frame(imputed.age) %>%
ggplot(aes(x=imputed.age)) + geom_histogram()
mean(imputed.age)
mean(imputed.age)
mean(titanic3$age)
mean(age)
mean(titanic3$age)
# After the imputation
newdata = titanic3
library(dplyr)
library(PASWR)
library(VIM)
library(mice)
library(ggplot2)
# Your code here
# Before the imputation
titanic3 %>%
select(age) %>%
ggplot(aes(x=age)) + geom_histogram()
# After the imputation
newdata = titanic3
newdata$age[is.na(newdata$age)] = mean(newdata$age, na.rm=TRUE)
newdata %>%
select(age) %>%
ggplot(aes(x=age)) + geom_histogram()
mean(newdata$age)
# The probelm is that there are so many missing age data which makes a huge bump around the mean age.
mean(titanic3$age)
md.pattern(titanic3)
rm(titanic3)
library(dplyr)
library(PASWR)
library(VIM)
library(mice)
library(ggplot2)
# Your code here
# Before the imputation
titanic3 %>%
select(age) %>%
ggplot(aes(x=age)) + geom_histogram()
# After the imputation
newdata = titanic3
newdata$age[is.na(newdata$age)] = mean(newdata$age, na.rm=TRUE)
newdata %>%
select(age) %>%
ggplot(aes(x=age)) + geom_histogram()
mean(newdata$age)
# The probelm is that there are so many missing age data which makes a huge bump around the mean age.
mean(titanic3$age)
titanic3$age
# Your code here
library(dplyr)
library(PASWR)
library(VIM)
library(mice)
library(ggplot2)
library(Hmisc)
#Before the imputation
titanic3 %>%
select(age) %>%
ggplot(aes(x=age)) + geom_histogram()
mean(titanic3$age)
#After the imputation
set.seed(0)
imputed.age = impute(titanic3$age, "random")
data.frame(imputed.age) %>%
ggplot(aes(x=imputed.age)) + geom_histogram()
mean(imputed.age)
# Your code here
library(dplyr)
library(PASWR)
library(VIM)
library(mice)
library(ggplot2)
library(Hmisc)
set.seed(0)
imputed.fare = impute(titanic3$fare, "random")
data.frame(imputed.fare) %>%
ggplot(aes(x=imputed.fare)) + geom_histogram()
titanic3 %>%
select(fare) %>%
ggplot(aes(x=imputed.fare)) + geom_histogram()
# Your code here
library(dplyr)
library(PASWR)
library(VIM)
library(mice)
library(ggplot2)
library(Hmisc)
titanic3 %>%
select(fare) %>%
ggplot(aes(x=imputed.fare)) + geom_histogram()
set.seed(0)
imputed.fare = impute(titanic3$fare, "random")
data.frame(imputed.fare) %>%
ggplot(aes(x=imputed.fare)) + geom_histogram()
titanic3 %>%
ggplot(aes(x=age,color=pclass)) + geom_histogram()
newdata$age = impute(newdata$age,"random")
newdata$fare = impute(newdata$age,"random")
newdata %>%
ggplot(aes(x=fare,y=age,color=pclass)) + geom_point(position="identity")
# Your code here
library(dplyr)
library(PASWR)
library(VIM)
library(mice)
library(ggplot2)
library(Hmisc)
newdata = titanic3
newdata$age = impute(newdata$age,"random")
newdata$fare = impute(newdata$fare,"random")
newdata %>%
ggplot(aes(x=fare,y=age,color=pclass)) + geom_point(position="identity")
# Your code here
library(dplyr)
library(PASWR)
library(VIM)
library(mice)
library(ggplot2)
library(Hmisc)
newdata = titanic3
newdata$age = impute(newdata$age,"random")
newdata$fare = impute(newdata$fare,"random")
newdata %>%
ggplot(aes(x=age,y=fare,color=pclass)) + geom_point(position="identity")
newdata %>%
ggplot(aes(x=age,y=fare,color=pclass)) + geom_point(position="identity") +
geom_smooth(method='lm',formula=y~x)
newdata %>%
ggplot(aes(x=age,y=fare)) + geom_point(position="identity") +
geom_smooth(method='lm',formula=y~x)
newdata %>%
ggplot(aes(x=age,y=fare,color=pclass)) + geom_point(position="identity") +
geom_smooth(method='lm',formula=y~x)
newdata %>%
ggplot(aes(x=age,y=fare,color=pclass)) + geom_point(position="identity") +
geom_smooth(method='lm',formula=y~x) + geom_point(aes(x=50,y=400))
# Your code here
library(dplyr)
library(PASWR)
library(VIM)
library(mice)
library(ggplot2)
library(Hmisc)
newdata = titanic3
newdata$age = impute(newdata$age,"random")
newdata$fare = impute(newdata$fare,"random")
newdata %>%
ggplot(aes(x=age,y=fare,color=pclass)) + geom_point(position="identity") +
geom_smooth(method='lm',formula=y~x) + geom_point(aes(x=c(50,10),y=c(400,100))
# Your code here
library(dplyr)
library(PASWR)
library(VIM)
library(mice)
library(ggplot2)
library(Hmisc)
newdata = titanic3
newdata$age = impute(newdata$age,"random")
newdata$fare = impute(newdata$fare,"random")
newdata %>%
ggplot(aes(x=age,y=fare,color=pclass)) + geom_point(position="identity") +
geom_smooth(method='lm',formula=y~x) + geom_point(aes(x=c(50,10),y=c(400,100)))
newdata %>%
ggplot(aes(x=age,y=fare,color=pclass)) + geom_point(position="identity") +
geom_smooth(method='lm',formula=y~x) + geom_point(aes(x=50,y=400)) +
geom_point(aes(x=10,y=100))
# Your code here
newdata = titanic3
newdata$age = impute(newdata$age,"random")
newdata$fare = impute(newdata$fare,"random")
#############################
#####K-Nearest Neighbors#####
#############################
#Recreating a dataset that has missing values.
missing.data = data.frame(x1 = 1:20, x2 = c(1:10, rep(NA, 10)))
missing.data
#Imputing using 1NN.
imputed.1nn = kNN(missing.data, k=1)
imputed.1nn
# Your code here
newdata = titanic3
newdata$age = impute(newdata$age,"random")
newdata$fare = impute(newdata$fare,"random")
more_passenger <- newdata %>%
select(age,fare)
more_passenger <- rbind(more_passenger,c(50,400),c(10,100))
View(more_passenger)
more_passenger <- cbind(more_passenger,newdata$pclass)
# Your code here
newdata = titanic3
newdata$age = impute(newdata$age,"random")
newdata$fare = impute(newdata$fare,"random")
more_passenger <- newdata %>%
select(age,fare,pclass)
more_passenger <- rbind(more_passenger,c(50,400,NA),c(10,100,NA))
imputed.1nn
iris.example = iris[, c(1, 2, 5)] #For illustration purposes, pulling only the
set.seed(0)
iris.example$Sepal.Length = jitter(iris.example$Sepal.Length, factor = .5)
iris.example$Sepal.Width = jitter(iris.example$Sepal.Width, factor= .5)
col.vec = c(rep("red", 50), #Creating a color vector for plotting purposes.
rep("green", 50),
rep("blue", 50))
plot(iris.example$Sepal.Length, iris.example$Sepal.Width,
col = col.vec, pch = 16,
main = "Sepal Measurements of Iris Data")
legend("topleft", c("Setosa", "Versicolor", "Virginica"),
pch = 16, col = c("red", "green", "blue"), cex = .75)
missing.vector = c(41:50, 91:100, 141:150) #Inducing missing values on the Species
iris.example$Species[missing.vector] = NA  #vector for each category.
iris.example
col.vec[missing.vector] = "purple" #Creating a new color vector to
plot(iris.example$Sepal.Length, iris.example$Sepal.Width,
col = col.vec, pch = 16,
main = "Sepal Measurements of Iris Data")
legend("topleft", c("Setosa", "Versicolor", "Virginica", "NA"),
pch = 16, col = c("red", "green", "blue", "purple"), cex = .75)
#Inspecting the Voronoi tesselation for the complete observations in the iris
#dataset.
library(deldir) #Load the Delaunay triangulation and Dirichelet tesselation library.
info = deldir(iris.example$Sepal.Length[-missing.vector],
iris.example$Sepal.Width[-missing.vector])
plot.tile.list(tile.list(info),
fillcol = col.vec[-missing.vector],
main = "Iris Voronoi Tessellation\nDecision Boundaries")
#Adding the observations that are missing species information.
points(iris.example$Sepal.Length[missing.vector],
iris.example$Sepal.Width[missing.vector],
pch = 16, col = "white")
points(iris.example$Sepal.Length[missing.vector],
iris.example$Sepal.Width[missing.vector],
pch = "?", cex = .66)
#Conducting a 1NN classification imputation.
iris.imputed1NN = kNN(iris.example, k = 1)
imputed.1nn = kNN(more_passenger, k=1)
imputed.1nn
# Your code here
newdata = titanic3
newdata$age = impute(newdata$age,"random")
newdata$fare = impute(newdata$fare,"random")
more_passenger <- newdata %>%
select(age,fare,pclass)
more_passenger <- rbind(more_passenger,c(50,400,NA),c(10,100,NA))
imputed.1nn = kNN(more_passenger, k=1)
imputed.1nn
# Your code here
newdata = titanic3
newdata$age = impute(newdata$age,"random")
newdata$fare = impute(newdata$fare,"random")
more_passenger <- newdata %>%
select(age,fare,pclass)
more_passenger <- rbind(more_passenger,c(50,400,NA),c(10,100,NA))
imputed.1nn = kNN(more_passenger, k=1)
imputed.1nn
# Your code here
newdata = titanic3
newdata$age = impute(newdata$age,"random")
newdata$fare = impute(newdata$fare,"random")
# more_passenger <- newdata %>%
#   select(age,fare,pclass)
# more_passenger <- rbind(more_passenger,c(50,400,NA),c(10,100,NA))
# imputed.1nn = kNN(more_passenger, k=1)
# imputed.1nn
md.pattern(newdata)
more_passenger <- rbind(more_passenger,c(50,400,NA),c(10,100,NA))
more_passenger
# Your code here
newdata = titanic3
newdata$age = impute(newdata$age,"random")
newdata$fare = impute(newdata$fare,"random")
md.pattern(newdata)
more_passenger <- newdata %>%
select(age,fare,pclass)
more_passenger <- rbind(more_passenger,c(50,400,NA),c(10,100,NA))
more_passenger
# imputed.1nn = kNN(more_passenger, k=1)
# imputed.1nn
md.pattern(more_passenger)
table(newdata$pclass, imputed.1nn$pclass)
table(more_passenger$pclass, imputed.1nn$pclass)
#Assessing the results by comparing to the truth known by the original dataset.
table(iris$Species, iris.imputed1NN$Species)
md.pattern(more_passenger$pclass)
md.pattern(more_passenger)
md.pattern(imputed.1nn)
imputed.1nn
length(imputed.1nn$pclass)
# Your code here
newdata = titanic3
newdata$age = impute(newdata$age,"random")
newdata$fare = impute(newdata$fare,"random")
md.pattern(newdata)
more_passenger <- newdata %>%
select(age,fare,pclass)
more_passenger <- rbind(more_passenger,c(50,400,NA),c(10,100,NA))
more_passenger
imputed.1nn = kNN(more_passenger, k=1)
imputed.1nn
imputed.1nn %>%
filter(pclass_imp==T)
sqrt(nrow(more_passenger))
imputed.36nn = kNN(more_passenger,k=36)
imputed.36nn %>%
filter(pclass_imp==T)
# Your code here
data2 <- titanic3 %>%
select(pclass,survived,sex,age,sibsp,parch)
data2 <- cbind(data2,newdata$fare)
md.pattern(data2)
# Your code here
full <- data2 %>%
filter(age!=NA)
# Your code here
full <- data2 %>%
filter(age is NULL)
# Your code here
full <- data2 %>%
filter(age!=NULL)
# Your code here
full <- data2 %>%
filter(age!=NA)
miss <- data2 %>%
filter(age==NA)
md.pattern(miss)
md.pattern(full)
md.pattern(data2)
is.na(data2$age)
# Your code here
full <- data2 %>%
filter(is.na(data2$age) == F)
miss <- data2 %>%
filter(is.na(data2$age) == T)
md.pattern(miss)
# Your code here
# Manhattan distance
library(knn)
# Your code here
# Manhattan distance
library(kknn)
data2.manhattan = kknn(age ~ ., full, miss, k = 1, distance = 1)
summary(data2.manhattan)
##################################################
#####Using Minkowski Distance Measures in KNN#####
##################################################
library(kknn) #Load the weighted knn library.
#Separating the complete and missing observations for use in the kknn() function.
complete = iris.example[-missing.vector, ]
missing = iris.example[missing.vector, -3]
#Distance corresponds to the Minkowski power.
iris.euclidean = kknn(Species ~ ., complete, missing, k = 12, distance = 2)
summary(iris.euclidean) #probability output, telling us the probability of beloning to
iris.manhattan = kknn(Species ~ ., complete, missing, k = 12, distance = 1)
summary(iris.manhattan)
Species
summary(data2.manhattan)
getwd()
setwd("/Users/lujian/Desktop/Kaggle")
library(VIM)
library(mice)
library(dplyr)
train = read.csv("train.csv")
test = read.csv('test.csv')
full = rbidn(train,test)
full = rbind(train,test)
View(test)
View(train)
train = train[,-80]
full = rbind(train,test)
rbind(train,test)
names(train)
names(test)
train
train
names(train)
train = train[,-80]
names(train)
train = read.csv("train.csv")
names(train)
train = train[,-81]
test = read.csv('test.csv')
full = merge(train,test)
md.pattern(full)
library(VIM) #For the visualization and imputation of missing values.
help(sleep) #Inspecting the mammal sleep dataset.
sleep
summary(sleep) #Summary information for the sleep dataset.
sapply(sleep, sd) #Standard deviations for the sleep dataset; any issues?
aggr(sleep) #A graphical interpretation of the missing values and their
#combinations within the dataset.
library(mice) #Load the multivariate imputation by chained equations library.
md.pattern(sleep)
aggr(full)
aggr(sleep) #A graphical interpretation of the missing values and their
md.pattern(sleep) #Can also view this information from a data perspective.
names(full)
full = rbind(train,test)
aggr(full)
md.pattern(full)
aggr(full)
iris.meas = iris[, -5]
summary(iris.meas)
sapply(iris.meas, sd)
iris.scale = as.data.frame(scale(iris.meas))
summary(iris.scale)
sapply(iris.scale, sd)
#Visualizing the width measurements.
plot(iris.scale$Petal.Width, iris.scale$Sepal.Width,
xlab = "Petal Width", ylab = "Sepal Width",
main = "Scaled Iris Data")
set.seed(0)
km.iris = kmeans(iris.scale, centers = 3)
#Inspecting the output of the kmeans() function.
km.iris
par(mfrow = c(1, 2))
plot(iris.scale$Petal.Width, iris.scale$Sepal.Width,
xlab = "Petal Width", ylab = "Sepal Width",
main = "Single K-Means Attempt", col = km.iris$cluster)
plot(iris.scale$Petal.Width, iris.scale$Sepal.Width,
xlab = "Petal Width", ylab = "Sepal Width",
main = "True Species", col = iris$Species)
#Visualizing the width measurements.
plot(iris.scale$Petal.Width, iris.scale$Sepal.Width,
xlab = "Petal Width", ylab = "Sepal Width",
main = "Scaled Iris Data")
set.seed(0)
km.iris = kmeans(iris.scale, centers = 3)
#Inspecting the output of the kmeans() function.
km.iris
par(mfrow = c(1, 1))
plot(iris.scale$Petal.Width, iris.scale$Sepal.Width,
xlab = "Petal Width", ylab = "Sepal Width",
main = "Single K-Means Attempt", col = km.iris$cluster)
points(km.iris$centers[, 4], km.iris$centers[, 2], pch = 16, col = "blue")
wssplot = function(data, nc = 15, seed = 0) {
wss = (nrow(data) - 1) * sum(apply(data, 2, var))
for (i in 2:nc) {
set.seed(seed)
wss[i] = sum(kmeans(data, centers = i, iter.max = 100, nstart = 100)$withinss)
}
plot(1:nc, wss, type = "b",
xlab = "Number of Clusters",
ylab = "Within-Cluster Variance",
main = "Scree Plot for the K-Means Procedure")
}
#Visualizing the scree plot for the scaled iris data; 3 seems like a plausible
#choice.
wssplot(iris.scale)
install.packages('flexclust')
library(flexclust) #Loading the flexclust library.
data(nutrient) #Loading the nutrient data.
help(nutrient) #Inspecting the data set; nutrients in meat, fish, and fowel.
nutrient
#Notice that the nutrient columns are in different measurements: calories,
#grams, and milligrams.
summary(nutrient)
summary(nutrient)
sapply(nutrient, sd)
nutrient.scaled = as.data.frame(scale(nutrient))
summary(nutrient.scaled)
sapply(nutrient.scaled, sd)
#We need to calcualte the pairwise distances between observations.
d = dist(nutrient.scaled)
fit.single = hclust(d, method = "single")
fit.complete = hclust(d, method = "complete")
fit.average = hclust(d, method = "average")
par(mfrow = c(1, 3))
plot(fit.single, hang = -1, main = "Dendrogram of Single Linkage")
plot(fit.complete, hang = -1, main = "Dendrogram of Complete Linkage")
plot(fit.average, hang = -1, main = "Dendrogram of Average Linkage")
#Cut the dendrogram into groups of data.
clusters.average = cutree(fit.average, k = 5)
clusters.average
#Viewing the groups of data.
table(clusters.average)
#Aggregating the original data by the cluster assignments.
aggregate(nutrient, by = list(cluster = clusters.average), median)
#Aggregating the scaled data by the cluster assignments.
aggregate(nutrient.scaled, by = list(cluster = clusters.average), median)
par(mfrow = c(1, 1))
plot(fit.average, hang = -1, main = "Dendrogram of Average Linkage\n5 Clusters")
rect.hclust(fit.average, k = 5)
train %>%
group_by(MSZoning) %>%
summarize(mean(SalePrice))
View(train)
train = read.csv("train.csv")
train %>%
group_by(MSZoning) %>%
summarize(mean(SalePrice))
aov(train)
